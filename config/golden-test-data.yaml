# Golden Test Data for MLOS E2E Validation
# ===============================================================================
#
# This file contains validated input/output pairs for inference testing.
# Each model has curated test cases with known expected outputs that can be
# validated programmatically.
#
# IMPORTANT: Core API Behavior
# ----------------------------
# - Core returns all tensors with the generic name "output"
# - Batch dimensions are typically squeezed/flattened
# - Multi-dimensional outputs are flattened to 1D arrays
# - Use include_outputs=true to get actual tensor data for validation
#
# Validation Types:
#   - output_exists: Validates an output tensor exists with expected size
#   - output_shape: Validates tensor shape matches expected
#   - status_success: Validates Core returns status=success
#   - top_k_contains: Validates top-K predictions contain expected classes
#   - generation_contains: Generated text must contain keywords (LLM only)
#
# Updated: 2024-12-12 - Aligned with Core API actual output behavior
# ===============================================================================

version: "1.0"

# ===============================================================================
# NLP MODELS - Text Classification, Language Modeling
# ===============================================================================

models:
  # ---------------------------------------------------------------------------
  # GPT-2 (DistilGPT2) - Causal Language Model
  # ---------------------------------------------------------------------------
  gpt2:
    description: "Text generation model - validates output tensor exists"
    test_cases:
      - name: "output_exists"
        input:
          text: "Hello, I am a language model"
          max_length: 16
        expected:
          validation_type: "output_exists"
          output_name: "output"
          # DistilGPT2 returns hidden states: seq_len * hidden_dim = 16 * 768 = 12288
          min_elements: 10000
          notes: "DistilGPT2 returns flattened tensor of shape [seq_len * hidden_dim]"

  # ---------------------------------------------------------------------------
  # BERT - Masked Language Model
  # ---------------------------------------------------------------------------
  bert:
    description: "Masked language model - validates inference produces output"
    test_cases:
      - name: "status_success"
        input:
          text: "The capital of France is [MASK]."
          max_length: 16
        expected:
          validation_type: "status_success"
          # BERT base produces ~930KB output for seq_len=3 (status response reports output_size)
          min_output_size: 100000
          notes: "BERT output_size validation (tensor data too large for curl transfer)"

  # ---------------------------------------------------------------------------
  # RoBERTa - Robust BERT variant
  # ---------------------------------------------------------------------------
  roberta:
    description: "Robust BERT - validates inference produces output"
    test_cases:
      - name: "status_success"
        input:
          text: "RoBERTa is great at understanding context."
          max_length: 16
        expected:
          validation_type: "status_success"
          # RoBERTa produces ~1.5MB output (status response reports output_size)
          min_output_size: 100000
          notes: "RoBERTa output_size validation (tensor data too large for curl transfer)"

  # ---------------------------------------------------------------------------
  # T5 - Text-to-Text Transformer (Encoder-Decoder)
  # ---------------------------------------------------------------------------
  t5:
    description: "Seq2seq model - encoder-decoder architecture"
    test_cases:
      - name: "encoder_decoder_response"
        input:
          text: "translate English to German: Hello"
          max_length: 16
          decoder_max_length: 8
        expected:
          validation_type: "status_success"
          notes: "T5 uses special encoder-decoder inference, validates status=success"

  # ---------------------------------------------------------------------------
  # DistilBERT - Smaller BERT variant
  # ---------------------------------------------------------------------------
  distilbert:
    description: "Distilled BERT - validates inference produces output"
    test_cases:
      - name: "status_success"
        input:
          text: "DistilBERT is smaller and faster."
          max_length: 12
        expected:
          validation_type: "status_success"
          # DistilBERT produces ~750KB output (status response reports output_size)
          min_output_size: 100000
          notes: "DistilBERT output_size validation (tensor data too large for curl transfer)"

  # ---------------------------------------------------------------------------
  # ALBERT - Parameter-efficient BERT
  # ---------------------------------------------------------------------------
  albert:
    description: "ALBERT - validates inference produces output"
    test_cases:
      - name: "status_success"
        input:
          text: "ALBERT uses parameter sharing."
          max_length: 10
        expected:
          validation_type: "status_success"
          # ALBERT produces ~600KB output (status response reports output_size)
          min_output_size: 100000
          notes: "ALBERT output_size validation (tensor data too large for curl transfer)"

  # ---------------------------------------------------------------------------
  # Sentence Transformers - Embedding Model
  # ---------------------------------------------------------------------------
  sentence-transformers:
    description: "Sentence embedding model - validates embedding output"
    test_cases:
      - name: "status_success"
        input:
          text: "This is a test sentence for embedding."
          max_length: 128
        expected:
          validation_type: "status_success"
          # Sentence transformers return hidden states for all tokens
          # Output size ~469KB exceeds reliable transfer limit
          min_output_size: 100000
          notes: "Sentence transformer returns hidden states (large output)"

# ===============================================================================
# VISION MODELS - Image Classification
# ===============================================================================

  # ---------------------------------------------------------------------------
  # ResNet-50 - CNN Image Classification
  # ---------------------------------------------------------------------------
  resnet:
    description: "ResNet-50 ImageNet classifier - validates classification output"
    test_cases:
      - name: "output_shape_validation"
        input:
          image_size: 224
          channels: 3
          seed: 42
        expected:
          validation_type: "output_shape"
          output_name: "output"
          # ImageNet: 1000 classes (batch dim squeezed)
          expected_shape: [1000]

  # ---------------------------------------------------------------------------
  # ViT - Vision Transformer
  # ---------------------------------------------------------------------------
  vit:
    description: "Vision Transformer - validates transformer-based classification"
    test_cases:
      - name: "output_shape_validation"
        input:
          image_size: 224
          channels: 3
          seed: 42
        expected:
          validation_type: "output_shape"
          output_name: "output"
          # ImageNet: 1000 classes (batch dim squeezed)
          expected_shape: [1000]

  # ---------------------------------------------------------------------------
  # ConvNeXt - Modern CNN
  # ---------------------------------------------------------------------------
  convnext:
    description: "ConvNeXt - modern CNN architecture"
    test_cases:
      - name: "output_shape_validation"
        input:
          image_size: 224
          channels: 3
          seed: 42
        expected:
          validation_type: "output_shape"
          output_name: "output"
          # ImageNet: 1000 classes
          expected_shape: [1000]

  # ---------------------------------------------------------------------------
  # MobileNet - Efficient Mobile Architecture
  # ---------------------------------------------------------------------------
  mobilenet:
    description: "MobileNetV2 - efficient mobile classifier"
    test_cases:
      - name: "output_shape_validation"
        input:
          image_size: 224
          channels: 3
          seed: 42
        expected:
          validation_type: "output_shape"
          output_name: "output"
          # MobileNetV2: Some versions have 1000 or 1001 classes
          expected_shape: [1001]

  # ---------------------------------------------------------------------------
  # DeiT - Data-efficient Image Transformer
  # ---------------------------------------------------------------------------
  deit:
    description: "DeiT - data-efficient ViT"
    test_cases:
      - name: "output_shape_validation"
        input:
          image_size: 224
          channels: 3
          seed: 42
        expected:
          validation_type: "output_shape"
          output_name: "output"
          # ImageNet: 1000 classes
          expected_shape: [1000]

  # ---------------------------------------------------------------------------
  # EfficientNet - Compound Scaling CNN
  # ---------------------------------------------------------------------------
  efficientnet:
    description: "EfficientNet-B0 - compound scaled CNN"
    test_cases:
      - name: "output_shape_validation"
        input:
          image_size: 224
          channels: 3
          seed: 42
        expected:
          validation_type: "output_shape"
          output_name: "output"
          # ImageNet: 1000 classes
          expected_shape: [1000]

# ===============================================================================
# MULTIMODAL MODELS
# ===============================================================================

  # ---------------------------------------------------------------------------
  # CLIP - Contrastive Language-Image Pretraining
  # ---------------------------------------------------------------------------
  clip:
    description: "CLIP - image-text similarity model"
    test_cases:
      - name: "status_success"
        input:
          text: "a photo of a cat"
          text_max_length: 77
          image_size: 224
          channels: 3
          seed: 42
        expected:
          validation_type: "status_success"
          # CLIP returns a single similarity score for text-image pairs
          notes: "CLIP returns text-image similarity score"

# ===============================================================================
# LLM MODELS (GGUF Format)
# ===============================================================================

  # ---------------------------------------------------------------------------
  # TinyLlama - Small Chat Model
  # ---------------------------------------------------------------------------
  tinyllama:
    description: "TinyLlama 1.1B GGUF - validates text generation"
    test_cases:
      - name: "basic_generation"
        input:
          prompt: "What is the capital of France?"
          max_tokens: 32
          temperature: 0.1
        expected:
          validation_type: "generation_contains"
          expected_keywords: ["Paris"]
          case_insensitive: true

      - name: "math_question"
        input:
          prompt: "What is 2 + 2?"
          max_tokens: 16
          temperature: 0.1
        expected:
          validation_type: "generation_contains"
          expected_keywords: ["4", "four"]
          case_insensitive: true

  # ---------------------------------------------------------------------------
  # Qwen2 0.5B - Ultra-small Instruction Model
  # ---------------------------------------------------------------------------
  qwen2-0.5b:
    description: "Qwen2 0.5B GGUF - validates instruction following"
    test_cases:
      - name: "simple_math"
        input:
          prompt: "What is 2 + 2? Answer with just the number."
          max_tokens: 8
          temperature: 0.1
        expected:
          validation_type: "generation_contains"
          expected_keywords: ["4"]
          notes: "Simple arithmetic - answer must contain '4'"

      - name: "multiplication"
        input:
          prompt: "What is 3 * 5? Answer with just the number."
          max_tokens: 8
          temperature: 0.1
        expected:
          validation_type: "generation_contains"
          expected_keywords: ["15"]
          notes: "Simple multiplication - answer must contain '15'"

      - name: "greeting_response"
        input:
          prompt: "Say hello in one word."
          max_tokens: 8
          temperature: 0.1
        expected:
          validation_type: "generation_contains"
          expected_keywords: ["Hello", "hello", "Hi", "hi"]

  # ---------------------------------------------------------------------------
  # Llama 3.2 1B - Meta's Small Model
  # ---------------------------------------------------------------------------
  llama-3.2-1b:
    description: "Llama 3.2 1B GGUF - validates instruction following"
    test_cases:
      - name: "capital_question"
        input:
          prompt: "What is the capital of Japan? Answer in one word."
          max_tokens: 16
          temperature: 0.1
        expected:
          validation_type: "generation_contains"
          expected_keywords: ["Tokyo"]
          notes: "Geography knowledge - answer must contain 'Tokyo'"

      - name: "simple_math"
        input:
          prompt: "What is 7 + 8? Answer with just the number."
          max_tokens: 8
          temperature: 0.1
        expected:
          validation_type: "generation_contains"
          expected_keywords: ["15"]
          notes: "Simple addition - answer must contain '15'"

  # ---------------------------------------------------------------------------
  # DeepSeek Coder 1.3B - Code Generation
  # ---------------------------------------------------------------------------
  deepseek-coder-1.3b:
    description: "DeepSeek Coder 1.3B GGUF - validates code generation"
    test_cases:
      - name: "python_function"
        input:
          prompt: "Write a Python function called 'add' that takes two numbers and returns their sum."
          max_tokens: 64
          temperature: 0.1
        expected:
          validation_type: "generation_contains"
          expected_keywords: ["def add", "return"]

      - name: "reverse_string"
        input:
          prompt: "Write a Python one-liner to reverse a string s."
          max_tokens: 32
          temperature: 0.1
        expected:
          validation_type: "generation_contains"
          expected_keywords: ["[::-1]", "reverse"]

# ===============================================================================
# ImageNet Class Labels Reference
# ===============================================================================
# Common ImageNet classes for validation:
#
# Dogs:
#   151: Chihuahua
#   207: golden retriever
#   208: Labrador retriever
#
# Cats:
#   281: tabby cat
#   282: tiger cat
#
# Common objects:
#   409: analog clock
#   504: coffee mug
#   817: sports car
#
# Reference: https://s3.amazonaws.com/onnx-model-zoo/synset.txt
# ===============================================================================
