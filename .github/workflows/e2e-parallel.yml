name: "[DEPRECATED] E2E Parallel Pipeline"

# ============================================================================
# DEPRECATED: This workflow is no longer used.
# Use e2e-unified.yml instead, which runs both kernel and userspace tests
# on the same machine for accurate performance comparison.
# ============================================================================

# Original triggers disabled:
# on:
#   schedule:
#     - cron: '0 0 * * 0'  # Weekly on Sunday at midnight UTC
#   workflow_dispatch:
#     inputs:
#       axon_version:
#         description: 'Axon version to test'
#         required: false
#         default: 'v3.1.9'
#       core_version:
#         description: 'Core version to test'
#         required: false
#         default: '6.1.0-alpha'
#       models:
#         description: |
#           Models to test (comma or space separated).
#         required: false
#         default: ''
#       parallel_jobs:
#         description: 'Number of parallel model tests (1 = sequential)'
#         required: false
#         default: '3'

# Placeholder trigger to keep file valid (never runs)
on:
  workflow_dispatch:
    inputs:
      deprecated:
        description: 'This workflow is deprecated. Use e2e-unified.yml instead.'
        required: true
        default: 'DO NOT USE'

permissions:
  contents: write
  pages: write
  id-token: write
  packages: read

jobs:
  # ============================================================================
  # SINGLE RUNNER: All tests on one machine for consistent performance metrics
  # ============================================================================
  e2e-test:
    name: E2E Test (Single Runner)
    runs-on: ubuntu-latest
    environment:
      name: github-pages
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Free up disk space
        run: |
          echo "Disk space before cleanup:"
          df -h
          # Aggressive cleanup for model conversion space
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo rm -rf /usr/local/share/boost
          sudo rm -rf /usr/share/swift
          sudo rm -rf /usr/local/julia*
          sudo rm -rf /opt/hostedtoolcache/go
          sudo rm -rf /opt/hostedtoolcache/node
          sudo docker image prune --all --force
          sudo apt-get clean
          sudo apt-get autoremove -y
          echo "Disk space after cleanup:"
          df -h
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          # Core dependencies + HuggingFace transformers + torchvision for semantic validation
          pip install pyyaml pillow numpy transformers torch torchvision
          sudo apt-get update && sudo apt-get install -y curl tar jq

      - name: Download golden images for vision model testing
        run: |
          chmod +x scripts/download-golden-images.sh
          ./scripts/download-golden-images.sh
      
      - name: Get enabled models from config/models.yaml
        id: get-models
        run: |
          # Normalize input: replace commas with spaces and clean up
          MODELS_INPUT=$(echo "${{ github.event.inputs.models }}" | tr ',' ' ' | xargs)
          EXCLUDE_INPUT=$(echo "${{ github.event.inputs.exclude_models }}" | tr ',' ' ' | xargs)
          
          # Get all enabled models from config/models.yaml
          ALL_ENABLED=$(python3 -c "
          import yaml
          import sys
          try:
              with open('config/models.yaml', 'r') as f:
                  config = yaml.safe_load(f)
              models = [name for name, m in config.get('models', {}).items() if m.get('enabled', False)]
              print(' '.join(models))
          except Exception as e:
              print(f'Error reading config/models.yaml: {e}', file=sys.stderr)
              sys.exit(1)
          ")
          
          if [ -z "$ALL_ENABLED" ]; then
            echo "âŒ Error: No enabled models found in config/models.yaml"
            echo "Please check config/models.yaml and ensure at least one model has enabled: true"
            exit 1
          fi
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ðŸ“‹ All enabled models in config/models.yaml:"
          echo "   $ALL_ENABLED"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # If models input is provided, use it (select specific models)
          if [ -n "$MODELS_INPUT" ]; then
            echo "âœ… Using provided models: $MODELS_INPUT"
            MODELS="$MODELS_INPUT"
          else
            # Otherwise use all enabled models from config/models.yaml, then exclude if specified
            MODELS="$ALL_ENABLED"
            if [ -n "$EXCLUDE_INPUT" ]; then
              echo "ðŸš« Excluding models: $EXCLUDE_INPUT"
              # Remove excluded models from the list
              for exclude in $EXCLUDE_INPUT; do
                MODELS=$(echo "$MODELS" | sed "s/\b$exclude\b//g" | xargs)
              done
            fi
          fi
          
          # Validate models exist in config/models.yaml and are enabled
          if [ -n "$MODELS" ]; then
            INVALID_MODELS=""
            DISABLED_MODELS=""
            for model in $MODELS; do
              if ! echo "$ALL_ENABLED" | grep -q "\b$model\b"; then
                # Check if model exists but is disabled
                EXISTS=$(python3 -c "
                import yaml
                with open('config/models.yaml') as f:
                    config = yaml.safe_load(f)
                print('yes' if '$model' in config.get('models', {}) else 'no')
                " 2>/dev/null || echo "no")
                if [ "$EXISTS" = "yes" ]; then
                  DISABLED_MODELS="$DISABLED_MODELS $model"
                else
                  INVALID_MODELS="$INVALID_MODELS $model"
                fi
              fi
            done
            
            if [ -n "$INVALID_MODELS" ]; then
              echo "âš ï¸ Warning: Invalid models specified (not in config/models.yaml):$INVALID_MODELS"
              echo "Available models: $ALL_ENABLED"
              # Remove invalid models
              for invalid in $INVALID_MODELS; do
                MODELS=$(echo "$MODELS" | sed "s/\b$invalid\b//g" | xargs)
              done
            fi
            
            if [ -n "$DISABLED_MODELS" ]; then
              echo "âš ï¸ Warning: Models exist but are disabled in config/models.yaml:$DISABLED_MODELS"
              echo "Enable them in config/models.yaml by setting enabled: true"
              # Remove disabled models
              for disabled in $DISABLED_MODELS; do
                MODELS=$(echo "$MODELS" | sed "s/\b$disabled\b//g" | xargs)
              done
            fi
          fi
          
          # Final validation
          if [ -z "$MODELS" ]; then
            echo "âŒ Error: No valid models to test"
            echo "Available enabled models in config/models.yaml: $ALL_ENABLED"
            echo ""
            echo "To fix:"
            echo "  1. Check config/models.yaml for enabled models"
            echo "  2. Or specify models in the workflow input"
            exit 1
          fi
          
          echo "models=$MODELS" >> $GITHUB_OUTPUT
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âœ… Final models to test: $MODELS"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
      
      - name: Download Axon release
        id: axon-download
        run: |
          START_TIME=$(date +%s%3N)
          
          VERSION="${{ github.event.inputs.axon_version || 'v3.1.9' }}"
          OS="linux"
          ARCH=$(uname -m)
          case $ARCH in
            x86_64) ARCH="amd64" ;;
            aarch64) ARCH="arm64" ;;
          esac

          ARTIFACT="axon_${VERSION#v}_${OS}_${ARCH}.tar.gz"
          URL="https://github.com/mlOS-foundation/axon/releases/download/${VERSION}/${ARTIFACT}"

          echo "ðŸ“¥ Downloading Axon from: $URL"
          mkdir -p ~/.local/bin
          curl -L -f -o "/tmp/${ARTIFACT}" "$URL"
          tar -xzf "/tmp/${ARTIFACT}" -C ~/.local/bin
          chmod +x ~/.local/bin/axon
          ~/.local/bin/axon version
          
          END_TIME=$(date +%s%3N)
          AXON_DOWNLOAD_MS=$((END_TIME - START_TIME))
          echo "axon_download_ms=$AXON_DOWNLOAD_MS" >> $GITHUB_OUTPUT
          echo "â±ï¸ Axon download: ${AXON_DOWNLOAD_MS}ms"
      
      - name: Download converter image (ONCE)
        run: |
          VERSION="${{ github.event.inputs.axon_version || 'v3.1.9' }}"
          VERSION_NO_V=${VERSION#v}
          OS="linux"
          ARCH=$(uname -m)
          case $ARCH in
            x86_64) ARCH="amd64" ;;
            aarch64) ARCH="arm64" ;;
          esac

          CONVERTER="axon-converter-${VERSION_NO_V}-${OS}-${ARCH}.tar.gz"
          URL="https://github.com/mlOS-foundation/axon/releases/download/${VERSION}/${CONVERTER}"
          IMAGE_TAG="ghcr.io/mlos-foundation/axon-converter:${VERSION_NO_V}"
          
          echo "ðŸ“¥ Downloading converter image (once for all models)..."
          echo "   Trying release artifact: ${URL}"
          
          # Try downloading from release first
          if curl -L -f -o "/tmp/${CONVERTER}" "$URL" 2>/dev/null; then
            docker load -i "/tmp/${CONVERTER}"
            docker tag "$IMAGE_TAG" "ghcr.io/mlos-foundation/axon-converter:latest" || true
            echo "âœ… Converter image loaded from release artifact"
          else
            echo "âš ï¸ Release artifact not found, trying registry..."
            # Fallback: pull directly from registry
            if docker pull "$IMAGE_TAG" 2>/dev/null; then
              docker tag "$IMAGE_TAG" "ghcr.io/mlos-foundation/axon-converter:latest" || true
              echo "âœ… Converter image pulled from registry"
            else
              echo "âš ï¸ Converter image not available in release or registry, will use fallback"
            fi
          fi
      
      - name: Download Core release (ONCE)
        id: core-download
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          START_TIME=$(date +%s%3N)

          VERSION="${{ github.event.inputs.core_version || '6.1.0-alpha' }}"
          # Normalize version: strip 'v' prefix for artifact filename (Core always publishes without v prefix)
          VERSION_NO_V="${VERSION#v}"
          # Release tag always has 'v' prefix
          RELEASE_TAG="v${VERSION_NO_V}"

          OS="linux"
          ARCH=$(uname -m)
          case $ARCH in
            x86_64) ARCH="amd64" ;;
            aarch64) ARCH="arm64" ;;
          esac

          mkdir -p ~/mlos-core

          # Artifact filename always uses version without 'v' prefix
          ARTIFACT="mlos-core_${VERSION_NO_V}_${OS}-${ARCH}.tar.gz"

          # Try gh CLI first (from mlOS-foundation/core repo)
          echo "ðŸ“¥ Trying gh download from core repo: $ARTIFACT (tag: $RELEASE_TAG)"
          if gh release download "${RELEASE_TAG}" --pattern "$ARTIFACT" --repo mlOS-foundation/core -D /tmp 2>/dev/null; then
            echo "âœ… Downloaded via gh CLI from core"
            tar -xzf "/tmp/$ARTIFACT" -C ~/mlos-core
          else
            # Fallback to core-releases public repo
            URL="https://github.com/mlOS-foundation/core-releases/releases/download/${RELEASE_TAG}/${ARTIFACT}"
            echo "ðŸ“¥ Trying curl from core-releases: $URL"
            if curl -L -f -o "/tmp/core.tar.gz" "$URL" 2>/dev/null; then
              echo "âœ… Downloaded via curl from core-releases"
              tar -xzf "/tmp/core.tar.gz" -C ~/mlos-core
            else
              echo "âŒ Failed to download Core"
              echo "   Release tag: $RELEASE_TAG"
              echo "   Artifact: $ARTIFACT"
              exit 1
            fi
          fi
          
          # Download ONNX Runtime
          ONNX_ARCH="x64"
          [ "$(uname -m)" = "aarch64" ] && ONNX_ARCH="aarch64"
          curl -L -f -o /tmp/onnx.tgz "https://github.com/microsoft/onnxruntime/releases/download/v1.18.0/onnxruntime-linux-${ONNX_ARCH}-1.18.0.tgz"
          mkdir -p ~/mlos-core/build
          tar -xzf /tmp/onnx.tgz -C ~/mlos-core/build
          mv ~/mlos-core/build/onnxruntime-* ~/mlos-core/build/onnxruntime
      
          END_TIME=$(date +%s%3N)
          CORE_DOWNLOAD_MS=$((END_TIME - START_TIME))
          echo "core_download_ms=$CORE_DOWNLOAD_MS" >> $GITHUB_OUTPUT
          echo "â±ï¸ Core download: ${CORE_DOWNLOAD_MS}ms"
      
      - name: Run format detection tests (Core PR #39)
        id: format-detection
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ðŸ” Testing Format-Agnostic Model Detection"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

          # Run format detection tests if script exists
          if [ -x ./test-format-detection.sh ]; then
            # Set CORE_DIR to point to downloaded Core
            export CORE_DIR=~/mlos-core
            export LOCAL_CORE_BINARY=$(find ~/mlos-core -name "mlos_core" -type f 2>/dev/null | head -1)

            ./test-format-detection.sh || echo "âš ï¸ Format detection tests had issues (non-blocking)"
          else
            echo "â„¹ï¸ Format detection test script not found, skipping"
          fi
          echo ""

      - name: Start Core server (ONCE)
        id: core-startup
        run: |
          START_TIME=$(date +%s%3N)

          cd ~/mlos-core
          BINARY=$(find . -name "mlos_core" -o -name "mlos-server" 2>/dev/null | head -1)
          if [ -z "$BINARY" ]; then
            # Try nested directory
            BINARY=$(find . -type f -executable -name "mlos_core" 2>/dev/null | head -1)
          fi

          if [ -z "$BINARY" ]; then
            echo "âŒ Core binary not found"
            find . -type f -name "*mlos*" 2>/dev/null
            exit 1
          fi

          echo "ðŸ“ Found Core binary: $BINARY"
          chmod +x "$BINARY"

          # Find llama.cpp libs (in release package or extracted dir)
          BINARY_DIR=$(dirname "$BINARY")
          LLAMA_LIB=""
          if [ -d "$BINARY_DIR/llama.cpp/lib" ]; then
            LLAMA_LIB="$BINARY_DIR/llama.cpp/lib"
          elif [ -d "$(pwd)/llama.cpp/lib" ]; then
            LLAMA_LIB="$(pwd)/llama.cpp/lib"
          fi

          export LD_LIBRARY_PATH="$(pwd)/build/onnxruntime/lib:${LLAMA_LIB}:$LD_LIBRARY_PATH"
          echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH" >> $GITHUB_ENV
          echo "ðŸ“š Library paths: ONNX=$(pwd)/build/onnxruntime/lib, llama.cpp=${LLAMA_LIB:-not found}"

          # Detect kernel mode - check if mlos-ml kernel module is loaded
          KERNEL_MODE="userspace"
          KERNEL_MODULE_LOADED="false"
          if lsmod 2>/dev/null | grep -q "mlos_ml\|mlos-ml"; then
            KERNEL_MODULE_LOADED="true"
            # Try to determine kernel mode from module parameters or Core config
            if [ -f /sys/module/mlos_ml/parameters/enable_scheduler ] && [ "$(cat /sys/module/mlos_ml/parameters/enable_scheduler 2>/dev/null)" = "1" ]; then
              if [ -f /sys/module/mlos_ml/parameters/enable_gpu_manager ] && [ "$(cat /sys/module/mlos_ml/parameters/enable_gpu_manager 2>/dev/null)" = "1" ]; then
                KERNEL_MODE="kernel_full"
              else
                KERNEL_MODE="kernel_sched"
              fi
            else
              KERNEL_MODE="kernel_basic"
            fi
          fi
          echo "kernel_mode=$KERNEL_MODE" >> $GITHUB_OUTPUT
          echo "kernel_module_loaded=$KERNEL_MODULE_LOADED" >> $GITHUB_OUTPUT
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ðŸ”§ MLOS Core Runtime Mode"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "   Mode: $KERNEL_MODE"
          echo "   Kernel Module Loaded: $KERNEL_MODULE_LOADED"
          if [ "$KERNEL_MODE" = "userspace" ]; then
            echo "   Description: Userspace-only inference (no kernel optimizations)"
          elif [ "$KERNEL_MODE" = "kernel_basic" ]; then
            echo "   Description: Kernel module with memory manager only"
          elif [ "$KERNEL_MODE" = "kernel_sched" ]; then
            echo "   Description: Kernel module with memory + scheduler"
          elif [ "$KERNEL_MODE" = "kernel_full" ]; then
            echo "   Description: Kernel module with all features (memory, scheduler, GPU manager)"
          fi
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

          # Start Core in background
          nohup $BINARY --http-port 18080 > /tmp/core.log 2>&1 &
          echo $! > /tmp/core.pid
          echo "ðŸš€ Core started with PID $(cat /tmp/core.pid)"

          # Wait for Core to be ready
          for i in {1..30}; do
            if curl -s http://127.0.0.1:18080/health >/dev/null 2>&1; then
              echo "âœ… Core server ready"
              break
            fi
            echo "â³ Waiting for Core... ($i/30)"
            sleep 1
          done

          if ! curl -s http://127.0.0.1:18080/health >/dev/null 2>&1; then
            echo "âŒ Core failed to start"
            cat /tmp/core.log
            exit 1
          fi

          END_TIME=$(date +%s%3N)
          CORE_STARTUP_MS=$((END_TIME - START_TIME))
          echo "core_startup_ms=$CORE_STARTUP_MS" >> $GITHUB_OUTPUT
          echo "â±ï¸ Core startup: ${CORE_STARTUP_MS}ms"

          # Measure Core idle resource usage
          sleep 2  # Let Core stabilize
          CORE_PID=$(cat /tmp/core.pid 2>/dev/null || echo "")
          if [ -n "$CORE_PID" ] && ps -p "$CORE_PID" > /dev/null 2>&1; then
            CORE_IDLE_CPU=$(ps -p "$CORE_PID" -o %cpu= 2>/dev/null | xargs || echo "0")
            CORE_IDLE_MEM_MB=$(ps -p "$CORE_PID" -o rss= 2>/dev/null | awk '{printf "%.0f", $1/1024}' || echo "0")
            echo "core_idle_cpu=$CORE_IDLE_CPU" >> $GITHUB_OUTPUT
            echo "core_idle_mem_mb=$CORE_IDLE_MEM_MB" >> $GITHUB_OUTPUT
            echo "ðŸ“Š Core idle: CPU=${CORE_IDLE_CPU}%, Memory=${CORE_IDLE_MEM_MB}MB"
          fi
      
      - name: Run all model tests
        id: test
        run: |
          MODELS="${{ steps.get-models.outputs.models }}"
          
          mkdir -p model-results
          chmod +x scripts/test-single-model.sh
          export PATH="$HOME/.local/bin:$PATH"
          
          # Start resource monitoring in background (captures max during tests)
          CORE_PID=$(cat /tmp/core.pid 2>/dev/null || echo "")
          if [ -n "$CORE_PID" ]; then
            # Use bash-based monitoring to avoid YAML heredoc issues
            (
              MAX_CPU=0
              MAX_MEM=0
              TOTAL_CPU=0
              TOTAL_MEM=0
              SAMPLES=0
              
              while ps -p "$CORE_PID" > /dev/null 2>&1; do
                CPU=$(ps -p "$CORE_PID" -o %cpu= 2>/dev/null | xargs || echo "0")
                MEM_KB=$(ps -p "$CORE_PID" -o rss= 2>/dev/null | xargs || echo "0")
                MEM_MB=$((MEM_KB / 1024))
                
                # Update max if higher (using awk for float comparison)
                if [ -n "$CPU" ] && [ -n "$MEM_MB" ]; then
                  CPU_FLOAT=$(echo "$CPU" | awk '{print $1+0}')
                  MAX_CPU_FLOAT=$(echo "$MAX_CPU" | awk '{print $1+0}')
                  
                  if awk "BEGIN {exit !($CPU_FLOAT > $MAX_CPU_FLOAT)}"; then
                    MAX_CPU=$CPU
                  fi
                  if [ "$MEM_MB" -gt "$MAX_MEM" ] 2>/dev/null; then
                    MAX_MEM=$MEM_MB
                  fi
                  
                  # Accumulate for average (using awk)
                  TOTAL_CPU=$(awk "BEGIN {print $TOTAL_CPU + $CPU_FLOAT}")
                  TOTAL_MEM=$((TOTAL_MEM + MEM_MB))
                  SAMPLES=$((SAMPLES + 1))
                  
                  # Write max values
                  echo "$MAX_CPU" > /tmp/core_max_cpu.txt
                  echo "$MAX_MEM" > /tmp/core_max_mem.txt
                  
                  # Write avg values
                  if [ $SAMPLES -gt 0 ]; then
                    AVG_CPU=$(awk "BEGIN {printf \"%.1f\", $TOTAL_CPU / $SAMPLES}")
                    AVG_MEM=$((TOTAL_MEM / SAMPLES))
                    echo "$AVG_CPU" > /tmp/core_avg_cpu.txt
                    echo "$AVG_MEM" > /tmp/core_avg_mem.txt
                  fi
                fi
                
                sleep 0.5
              done
            ) &
            MONITOR_PID=$!
            echo "ðŸ“Š Resource monitor started (PID: $MONITOR_PID) for Core PID: $CORE_PID"
          fi
          
          # Separate NLP (smaller, parallel OK) from Vision/Multimodal (larger, need sequential)
          NLP_MODELS=""
          VISION_MODELS=""
          MULTIMODAL_MODELS=""
          for model in $MODELS; do
            case "$model" in
              gpt2|bert|roberta|t5) NLP_MODELS="$NLP_MODELS $model" ;;
              clip) MULTIMODAL_MODELS="$MULTIMODAL_MODELS $model" ;;
              *) VISION_MODELS="$VISION_MODELS $model" ;;
            esac
          done
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ðŸ§ª Phase 1: NLP models (parallel:3) -$NLP_MODELS"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Run NLP models in parallel (smaller models, less disk usage)
          if [ -n "$NLP_MODELS" ]; then
            echo "$NLP_MODELS" | tr ' ' '\n' | grep -v '^$' | xargs -P 3 -I {} bash -c '
              export PATH="$HOME/.local/bin:$PATH"
              echo "ðŸ”„ [NLP] Starting: {}"
              ./scripts/test-single-model.sh "{}" \
                --output-dir model-results \
                --core-url http://127.0.0.1:18080 \
                || echo "âš ï¸ {} had issues"
            '
          fi
          
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ðŸ§ª Phase 2: Vision models (sequential) -$VISION_MODELS"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Run Vision models sequentially (large models, need disk cleanup between)
          # Enable golden images for semantic classification validation
          for model in $VISION_MODELS; do
            [ -z "$model" ] && continue
            echo "ðŸ”„ [Vision] Starting: $model"
            ./scripts/test-single-model.sh "$model" \
            --output-dir model-results \
            --core-url http://127.0.0.1:18080 \
            --golden-images \
              || echo "âš ï¸ $model had issues"

            # Show disk space after each vision model
            echo "ðŸ“Š Disk after $model: $(df -h / | tail -1 | awk '{print $4}') free"
          done
          
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ðŸ§ª Phase 3: Multimodal models (sequential) -$MULTIMODAL_MODELS"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Run Multimodal models sequentially (complex models, need sequential)
          for model in $MULTIMODAL_MODELS; do
            [ -z "$model" ] && continue
            echo "ðŸ”„ [Multimodal] Starting: $model"
            ./scripts/test-single-model.sh "$model" \
            --output-dir model-results \
            --core-url http://127.0.0.1:18080 \
              || echo "âš ï¸ $model had issues"
            
            # Show disk space after each multimodal model
            echo "ðŸ“Š Disk after $model: $(df -h / | tail -1 | awk '{print $4}') free"
          done
          
          # Stop monitor and get max values
          if [ -n "$MONITOR_PID" ]; then
            kill $MONITOR_PID 2>/dev/null || true
            wait $MONITOR_PID 2>/dev/null || true
            sleep 1
          fi
          
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âœ… All model tests completed"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          ls -la model-results/
          
          # Get max CPU/memory from monitoring
          if [ -f /tmp/core_max_cpu.txt ] && [ -f /tmp/core_max_mem.txt ]; then
            CORE_LOAD_CPU_MAX=$(cat /tmp/core_max_cpu.txt | head -1 || echo "0")
            CORE_LOAD_MEM_MAX_MB=$(cat /tmp/core_max_mem.txt | head -1 || echo "0")
            if [ -f /tmp/core_avg_cpu.txt ] && [ -f /tmp/core_avg_mem.txt ]; then
              CORE_LOAD_CPU_AVG=$(cat /tmp/core_avg_cpu.txt | head -1 || echo "$CORE_LOAD_CPU_MAX")
              CORE_LOAD_MEM_AVG_MB=$(cat /tmp/core_avg_mem.txt | head -1 || echo "$CORE_LOAD_MEM_MAX_MB")
            else
              # Fallback: use max as avg if no samples
              CORE_LOAD_CPU_AVG=$CORE_LOAD_CPU_MAX
              CORE_LOAD_MEM_AVG_MB=$CORE_LOAD_MEM_MAX_MB
            fi
          else
            # Fallback: measure current (may be idle)
            CORE_PID=$(cat /tmp/core.pid 2>/dev/null || echo "")
            if [ -n "$CORE_PID" ] && ps -p "$CORE_PID" > /dev/null 2>&1; then
              CORE_LOAD_CPU_MAX=$(ps -p "$CORE_PID" -o %cpu= 2>/dev/null | xargs || echo "0")
              CORE_LOAD_MEM_MAX_MB=$(ps -p "$CORE_PID" -o rss= 2>/dev/null | awk '{printf "%.0f", $1/1024}' || echo "0")
              CORE_LOAD_CPU_AVG=$CORE_LOAD_CPU_MAX
              CORE_LOAD_MEM_AVG_MB=$CORE_LOAD_MEM_MAX_MB
            else
              CORE_LOAD_CPU_MAX=0
              CORE_LOAD_MEM_MAX_MB=0
              CORE_LOAD_CPU_AVG=0
              CORE_LOAD_MEM_AVG_MB=0
            fi
          fi
          
          echo "core_load_cpu_max=$CORE_LOAD_CPU_MAX" >> $GITHUB_OUTPUT
          echo "core_load_cpu_avg=$CORE_LOAD_CPU_AVG" >> $GITHUB_OUTPUT
          echo "core_load_mem_max_mb=$CORE_LOAD_MEM_MAX_MB" >> $GITHUB_OUTPUT
          echo "core_load_mem_avg_mb=$CORE_LOAD_MEM_AVG_MB" >> $GITHUB_OUTPUT
          echo "ðŸ“Š Core under load: CPU=${CORE_LOAD_CPU_MAX}% (max), Memory=${CORE_LOAD_MEM_MAX_MB}MB (max)"
          
          # Measure Axon (if running)
          AXON_PID=$(pgrep -f "axon" | head -1 || echo "")
          if [ -n "$AXON_PID" ]; then
            AXON_CPU=$(ps -p "$AXON_PID" -o %cpu= 2>/dev/null | xargs || echo "0")
            AXON_MEM_MB=$(ps -p "$AXON_PID" -o rss= 2>/dev/null | awk '{printf "%.0f", $1/1024}' || echo "0")
            echo "axon_cpu=$AXON_CPU" >> $GITHUB_OUTPUT
            echo "axon_mem_mb=$AXON_MEM_MB" >> $GITHUB_OUTPUT
            echo "ðŸ“Š Axon: CPU=${AXON_CPU}%, Memory=${AXON_MEM_MB}MB"
          fi
        continue-on-error: true
      
      - name: Stop Core server
        if: always()
        run: |
          if [ -f /tmp/core.pid ]; then
            kill $(cat /tmp/core.pid) 2>/dev/null || true
            echo "ðŸ›‘ Core server stopped"
          fi
          
          echo "ðŸ“‹ Core logs:"
          cat /tmp/core.log 2>/dev/null | tail -100 || true
      
      - name: Collect hardware and timing info
        if: always()
        run: |
          mkdir -p model-results
          
          # Collect actual hardware info from runner
          cat > model-results/hardware-info.json << EOF
          {
            "os": "$(uname -s)",
            "os_version": "$(cat /etc/os-release 2>/dev/null | grep PRETTY_NAME | cut -d'"' -f2 || uname -r)",
            "arch": "$(uname -m)",
            "cpu_model": "$(lscpu 2>/dev/null | grep 'Model name' | cut -d':' -f2 | xargs || echo 'Unknown')",
            "cpu_cores": $(nproc --all 2>/dev/null || echo 2),
            "cpu_threads": $(nproc 2>/dev/null || echo 2),
            "memory_gb": $(free -g 2>/dev/null | awk '/^Mem:/{print $2}' || echo 7),
            "gpu_count": $(nvidia-smi -L 2>/dev/null | wc -l || echo 0),
            "gpu_name": "$(nvidia-smi --query-gpu=name --format=csv,noheader 2>/dev/null | head -1 || echo 'None')",
            "gpu_memory": "$(nvidia-smi --query-gpu=memory.total --format=csv,noheader 2>/dev/null | head -1 || echo 'N/A')",
            "disk_total": "$(df -h / | tail -1 | awk '{print $2}')",
            "disk_available": "$(df -h / | tail -1 | awk '{print $4}')"
          }
          EOF
          
          # Collect timing info from previous steps
          cat > model-results/timings-info.json << EOF
          {
            "axon_download_ms": ${{ steps.axon-download.outputs.axon_download_ms || 0 }},
            "core_download_ms": ${{ steps.core-download.outputs.core_download_ms || 0 }},
            "core_startup_ms": ${{ steps.core-startup.outputs.core_startup_ms || 0 }}
          }
          EOF
          
          # Collect resource usage info from previous steps
          cat > model-results/resources-info.json << EOF
          {
            "core_idle_cpu": ${{ steps.core-startup.outputs.core_idle_cpu || 0 }},
            "core_idle_mem_mb": ${{ steps.core-startup.outputs.core_idle_mem_mb || 0 }},
            "core_load_cpu_avg": ${{ steps.test.outputs.core_load_cpu_max || 0 }},
            "core_load_cpu_max": ${{ steps.test.outputs.core_load_cpu_max || 0 }},
            "core_load_mem_avg_mb": ${{ steps.test.outputs.core_load_mem_max_mb || 0 }},
            "core_load_mem_max_mb": ${{ steps.test.outputs.core_load_mem_max_mb || 0 }},
            "axon_cpu": ${{ steps.test.outputs.axon_cpu || 0 }},
            "axon_mem_mb": ${{ steps.test.outputs.axon_mem_mb || 0 }},
            "gpu_status": "Not used (CPU-only inference)",
            "kernel_mode": "${{ steps.core-startup.outputs.kernel_mode || 'userspace' }}",
            "kernel_module_loaded": ${{ steps.core-startup.outputs.kernel_module_loaded || 'false' }}
          }
          EOF
          
          echo "ðŸ“Š Hardware Info:"
          cat model-results/hardware-info.json
          echo ""
          echo "â±ï¸ Timing Info:"
          cat model-results/timings-info.json
      
      - name: Aggregate results
        if: always()
        env:
          AXON_VERSION: ${{ github.event.inputs.axon_version || 'v3.1.9' }}
          CORE_VERSION: ${{ github.event.inputs.core_version || '6.1.0-alpha' }}
        run: |
          mkdir -p output metrics

          python3 scripts/aggregate-results.py \
            --results-dir model-results \
            --output metrics/latest.json \
            --markdown output/RESULTS.md \
            --hardware-info model-results/hardware-info.json \
            --timings-info model-results/timings-info.json \
            --resources-info model-results/resources-info.json \
            --github-summary || echo "âš ï¸ Aggregation had issues"

          echo "ðŸ“Š Metrics:"
          cat metrics/latest.json 2>/dev/null || echo "{}"

      - name: Fetch kernel comparison data
        if: always()
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "ðŸ” Looking for latest kernel E2E results..."

          # Find the most recent successful kernel workflow run
          KERNEL_RUN=$(gh run list --workflow=e2e-kernel.yml --status=success --limit=1 --json databaseId --jq '.[0].databaseId' 2>/dev/null || echo "")

          if [ -n "$KERNEL_RUN" ] && [ "$KERNEL_RUN" != "null" ]; then
            echo "ðŸ“¦ Found kernel run: $KERNEL_RUN"

            # Get the actual artifact name using API (artifact names have run numbers)
            ARTIFACT_NAME=$(gh api "repos/${{ github.repository }}/actions/runs/${KERNEL_RUN}/artifacts" --jq '.artifacts[] | select(.name | startswith("kernel-e2e-results")) | .name' | head -1)

            if [ -n "$ARTIFACT_NAME" ]; then
              echo "ðŸ“¦ Found artifact: $ARTIFACT_NAME"

              # Download the kernel results artifact
              mkdir -p /tmp/kernel-data
              gh run download "$KERNEL_RUN" -n "$ARTIFACT_NAME" -D /tmp/kernel-data || true

              # List what we got
              echo "ðŸ“‚ Downloaded files:"
              find /tmp/kernel-data -type f | head -20

              # Look for kernel-comparison.json
              KERNEL_JSON=$(find /tmp/kernel-data -name "kernel-comparison.json" -type f | head -1)

              if [ -n "$KERNEL_JSON" ] && [ -f "$KERNEL_JSON" ]; then
                echo "âœ… Found kernel comparison data: $KERNEL_JSON"
                cat "$KERNEL_JSON" | head -30

                # Merge kernel_comparison into metrics/latest.json
                python3 << MERGE_SCRIPT
          import json
          from pathlib import Path

          metrics_file = Path('metrics/latest.json')
          kernel_file = Path('$KERNEL_JSON')

          if metrics_file.exists() and kernel_file.exists():
              with open(metrics_file) as f:
                  metrics = json.load(f)
              with open(kernel_file) as f:
                  kernel_data = json.load(f)

              # Add kernel comparison section
              metrics['kernel_comparison'] = kernel_data
              metrics['resources'] = metrics.get('resources', {})
              metrics['resources']['kernel_data_available'] = True

              with open(metrics_file, 'w') as f:
                  json.dump(metrics, f, indent=2)

              print("âœ… Merged kernel comparison into metrics")
          else:
              print("âš ï¸ Could not merge - missing files")
          MERGE_SCRIPT
              else
                echo "âš ï¸ No kernel-comparison.json found in downloaded artifacts"
              fi
            else
              echo "âš ï¸ No kernel artifact found in run $KERNEL_RUN"
            fi
          else
            echo "â„¹ï¸ No successful kernel workflow runs found"
          fi

      - name: Generate HTML report
        if: always()
        run: |
          python3 report/render.py \
            --metrics metrics/latest.json \
            --template report/template.html \
            --output output/index.html || echo "âš ï¸ Renderer failed"
          
          cp report/styles.css output/ 2>/dev/null || true
          
          # Fallback
          if [ ! -f output/index.html ]; then
            echo "<html><body><h1>E2E Results</h1><pre>$(cat output/RESULTS.md 2>/dev/null || echo 'No results')</pre></body></html>" > output/index.html
          fi
          
          ls -la output/
      
      - name: Upload metrics
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-metrics-${{ github.run_number }}
          path: metrics/
          retention-days: 90
      
      - name: Upload report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-report-${{ github.run_number }}
          path: output/
          retention-days: 90
      
      - name: Upload model results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-model-results-${{ github.run_number }}
          path: model-results/
          retention-days: 30
      
      - name: Upload logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-logs-${{ github.run_number }}
          path: /tmp/core.log
          retention-days: 30
      
      - name: Setup Pages
        if: always()
        uses: actions/configure-pages@v4
      
      - name: Prepare Pages artifact
        if: always()
        run: |
          # Create a clean output directory without symlinks or hard links
          mkdir -p ./output-clean
          # Copy all files recursively, breaking symlinks and hard links
          if [ -d ./output ]; then
            # Copy entire directory structure, breaking all symlinks and hard links
            # Use tar to copy, which naturally breaks links
            (cd ./output && tar -cf - .) | (cd ./output-clean && tar -xf -) 2>/dev/null || \
            # Fallback: use cp with proper options
            cp -rL --no-preserve=links ./output/. ./output-clean/ 2>/dev/null || true
            # Remove any remaining symlinks (shouldn't be any, but just in case)
            find ./output-clean -type l -delete 2>/dev/null || true
            # Remove large files (>10MB) to reduce size
            find ./output-clean -type f -size +10M -delete 2>/dev/null || true
            # Replace output with clean version
            rm -rf ./output
            mv ./output-clean ./output
            echo "âœ… Cleaned output directory (removed symlinks and hard links)"
          else
            echo "âš ï¸ Output directory not found"
          fi
          # Verify no symlinks or hard links remain
          SYMLINKS=$(find ./output -type l 2>/dev/null | wc -l)
          HARD_LINKS=$(find ./output -type f -links +1 2>/dev/null | wc -l)
          echo "Symlinks found: $SYMLINKS"
          echo "Hard links found: $HARD_LINKS"
          ls -lah ./output/ 2>/dev/null | head -20
          du -sh ./output/ 2>/dev/null || echo "Cannot check size"

      - name: Upload Pages artifact
        if: always()
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./output
      
      - name: Deploy to GitHub Pages
        if: always()
        id: deployment
        uses: actions/deploy-pages@v4
      
      - name: Summary
        if: always()
        run: |
          echo "## ðŸ“Š E2E Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸŒ **Report**: https://mlos-foundation.github.io/system-test/" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f metrics/latest.json ]; then
          echo -e "import json\ntry:\n    with open(\"metrics/latest.json\") as f:\n        m = json.load(f)\n    print(\"| Metric | Value |\")\n    print(\"|--------|-------|\")\n    total = m.get(\"total_models\", \"N/A\")\n    success = m.get(\"successful_models\", \"N/A\")\n    rate = m.get(\"success_rate\", \"N/A\")\n    print(\"| Models Tested | {}\" .format(total))\n    print(\"| Successful | {}\" .format(success))\n    print(\"| Success Rate | {}%\" .format(rate))\nexcept:\n    print(\"Results not available\")" > /tmp/summary.py && python3 /tmp/summary.py >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Benefits of Single Runner:" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Consistent hardware for all models" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Comparable performance metrics" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Single Core instance" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… No repeated downloads" >> $GITHUB_STEP_SUMMARY
