name: E2E Parallel Pipeline

on:
  workflow_dispatch:
    inputs:
      axon_version:
        description: 'Axon version to test'
        required: false
        default: 'v3.1.1'
      core_version:
        description: 'Core version to test'
        required: false
        default: '3.2.5-alpha'
      models:
        description: 'Comma-separated model names (empty = all enabled)'
        required: false
        default: ''
      parallel_jobs:
        description: 'Number of parallel model tests (1 = sequential)'
        required: false
        default: '3'

permissions:
  contents: write
  pages: write
  id-token: write
  packages: read

jobs:
  # ============================================================================
  # SINGLE RUNNER: All tests on one machine for consistent performance metrics
  # ============================================================================
  e2e-test:
    name: E2E Test (Single Runner)
    runs-on: ubuntu-latest
    environment:
      name: github-pages
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Free up disk space
        run: |
          echo "Disk space before cleanup:"
          df -h
          # Aggressive cleanup for model conversion space
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo rm -rf /usr/local/share/boost
          sudo rm -rf /usr/share/swift
          sudo rm -rf /usr/local/julia*
          sudo rm -rf /opt/hostedtoolcache/go
          sudo rm -rf /opt/hostedtoolcache/node
          sudo docker image prune --all --force
          sudo apt-get clean
          sudo apt-get autoremove -y
          echo "Disk space after cleanup:"
          df -h
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install pyyaml
          sudo apt-get update && sudo apt-get install -y curl tar jq
      
      - name: Get enabled models
        id: get-models
        run: |
          if [ -n "${{ github.event.inputs.models }}" ]; then
            MODELS="${{ github.event.inputs.models }}"
          else
            MODELS=$(python3 -c "
            import json
            try:
                with open('metrics/latest.json') as f:
                    m = json.load(f)
                    print(f"| Metric | Value |")
                    print(f"|--------|-------|")
                    print(f"| Models Tested | {m.get('total_models', 'N/A')} |")
                    print(f"| Successful | {m.get('successful_models', 'N/A')} |")
                    print(f"| Success Rate | {m.get('success_rate', 'N/A')}% |")
            except:
                print('Results not available')
          echo "## ðŸ“Š E2E Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸŒ **Report**: https://mlos-foundation.github.io/system-test/" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f metrics/latest.json ]; then
          python3 << 'PYTHON_SCRIPT'
import json
try:
    with open('metrics/latest.json') as f:
        m = json.load(f)
        print(f"| Metric | Value |")
        print(f"|--------|-------|")
        print(f"| Models Tested | {m.get('total_models', 'N/A')} |")
        print(f"| Successful | {m.get('successful_models', 'N/A')} |")
        print(f"| Success Rate | {m.get('success_rate', 'N/A')}% |")
except:
    print('Results not available')
PYTHON_SCRIPT >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Benefits of Single Runner:" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Consistent hardware for all models" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Comparable performance metrics" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Single Core instance" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… No repeated downloads" >> $GITHUB_STEP_SUMMARY
