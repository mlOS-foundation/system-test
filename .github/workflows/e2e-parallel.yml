name: E2E Parallel Pipeline

on:
  workflow_dispatch:
    inputs:
      axon_version:
        description: 'Axon version to test'
        required: false
        default: 'v3.1.1'
      core_version:
        description: 'Core version to test'
        required: false
        default: '3.2.5-alpha'
      models:
        description: 'Comma-separated model names (empty = all enabled)'
        required: false
        default: ''
      parallel_jobs:
        description: 'Number of parallel model tests (1 = sequential)'
        required: false
        default: '3'

permissions:
  contents: write
  pages: write
  id-token: write
  packages: read

jobs:
  # ============================================================================
  # SINGLE RUNNER: All tests on one machine for consistent performance metrics
  # ============================================================================
  e2e-test:
    name: E2E Test (Single Runner)
    runs-on: ubuntu-latest
    environment:
      name: github-pages
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Free up disk space
        run: |
          echo "Disk space before cleanup:"
          df -h
          # Aggressive cleanup for model conversion space
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo rm -rf /usr/local/share/boost
          sudo rm -rf /usr/share/swift
          sudo rm -rf /usr/local/julia*
          sudo rm -rf /opt/hostedtoolcache/go
          sudo rm -rf /opt/hostedtoolcache/node
          sudo docker image prune --all --force
          sudo apt-get clean
          sudo apt-get autoremove -y
          echo "Disk space after cleanup:"
          df -h
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install pyyaml
          sudo apt-get update && sudo apt-get install -y curl tar jq
      
      - name: Get enabled models
        id: get-models
        run: |
          if [ -n "${{ github.event.inputs.models }}" ]; then
            MODELS="${{ github.event.inputs.models }}"
          else
            MODELS=$(python3 -c "
          import yaml
          with open('config/models.yaml') as f:
              config = yaml.safe_load(f)
          models = [name for name, m in config.get('models', {}).items() if m.get('enabled', False)]
          print(' '.join(models))
          ")
          fi
          echo "models=$MODELS" >> $GITHUB_OUTPUT
          echo "ðŸ“‹ Models to test: $MODELS"
      
      - name: Download Axon release
        id: axon-download
        run: |
          START_TIME=$(date +%s%3N)
          
          VERSION="${{ github.event.inputs.axon_version || 'v3.1.1' }}"
          OS="linux"
          ARCH=$(uname -m)
          case $ARCH in
            x86_64) ARCH="amd64" ;;
            aarch64) ARCH="arm64" ;;
          esac
          
          ARTIFACT="axon_${VERSION#v}_${OS}_${ARCH}.tar.gz"
          URL="https://github.com/mlOS-foundation/axon/releases/download/${VERSION}/${ARTIFACT}"
          
          echo "ðŸ“¥ Downloading Axon from: $URL"
          mkdir -p ~/.local/bin
          curl -L -f -o "/tmp/${ARTIFACT}" "$URL"
          tar -xzf "/tmp/${ARTIFACT}" -C ~/.local/bin
          chmod +x ~/.local/bin/axon
          ~/.local/bin/axon version
          
          END_TIME=$(date +%s%3N)
          AXON_DOWNLOAD_MS=$((END_TIME - START_TIME))
          echo "axon_download_ms=$AXON_DOWNLOAD_MS" >> $GITHUB_OUTPUT
          echo "â±ï¸ Axon download: ${AXON_DOWNLOAD_MS}ms"
      
      - name: Download converter image (ONCE)
        run: |
          VERSION="${{ github.event.inputs.axon_version || 'v3.1.1' }}"
          OS="linux"
          ARCH=$(uname -m)
          case $ARCH in
            x86_64) ARCH="amd64" ;;
            aarch64) ARCH="arm64" ;;
          esac
          
          CONVERTER="axon-converter-${VERSION#v}-${OS}-${ARCH}.tar.gz"
          URL="https://github.com/mlOS-foundation/axon/releases/download/${VERSION}/${CONVERTER}"
          echo "ðŸ“¥ Downloading converter image (once for all models)..."
          if curl -L -f -o "/tmp/${CONVERTER}" "$URL" 2>/dev/null; then
            docker load -i "/tmp/${CONVERTER}"
            docker tag "ghcr.io/mlos-foundation/axon-converter:${VERSION#v}" "ghcr.io/mlos-foundation/axon-converter:latest" || true
            echo "âœ… Converter image loaded"
          else
            echo "âš ï¸ Converter image not available, will use fallback"
          fi
      
      - name: Download Core release (ONCE)
        id: core-download
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          START_TIME=$(date +%s%3N)
          
          VERSION="${{ github.event.inputs.core_version || '3.2.5-alpha' }}"
          OS="linux"
          ARCH=$(uname -m)
          case $ARCH in
            x86_64) ARCH="amd64" ;;
            aarch64) ARCH="arm64" ;;
          esac
          
          mkdir -p ~/mlos-core
          
          # Try gh CLI first
          ARTIFACT="mlos-core_${VERSION}_${OS}-${ARCH}.tar.gz"
          echo "ðŸ“¥ Trying gh download: $ARTIFACT"
          if gh release download "${VERSION}" --pattern "$ARTIFACT" --repo mlOS-foundation/core -D /tmp 2>/dev/null; then
            echo "âœ… Downloaded via gh CLI"
            tar -xzf "/tmp/$ARTIFACT" -C ~/mlos-core
          else
            # Fallback to core-releases
            RELEASE_TAG="v${VERSION}"
            [[ "$VERSION" =~ ^v ]] && RELEASE_TAG="$VERSION"
            URL="https://github.com/mlOS-foundation/core-releases/releases/download/${RELEASE_TAG}/${ARTIFACT}"
            echo "ðŸ“¥ Trying curl from: $URL"
            if curl -L -f -o "/tmp/core.tar.gz" "$URL" 2>/dev/null; then
              echo "âœ… Downloaded via curl"
          tar -xzf "/tmp/core.tar.gz" -C ~/mlos-core
            else
              echo "âŒ Failed to download Core"
              exit 1
            fi
          fi
          
          # Download ONNX Runtime
          ONNX_ARCH="x64"
          [ "$(uname -m)" = "aarch64" ] && ONNX_ARCH="aarch64"
          curl -L -f -o /tmp/onnx.tgz "https://github.com/microsoft/onnxruntime/releases/download/v1.18.0/onnxruntime-linux-${ONNX_ARCH}-1.18.0.tgz"
          mkdir -p ~/mlos-core/build
          tar -xzf /tmp/onnx.tgz -C ~/mlos-core/build
          mv ~/mlos-core/build/onnxruntime-* ~/mlos-core/build/onnxruntime
      
          END_TIME=$(date +%s%3N)
          CORE_DOWNLOAD_MS=$((END_TIME - START_TIME))
          echo "core_download_ms=$CORE_DOWNLOAD_MS" >> $GITHUB_OUTPUT
          echo "â±ï¸ Core download: ${CORE_DOWNLOAD_MS}ms"
      
      - name: Start Core server (ONCE)
        id: core-startup
        run: |
          START_TIME=$(date +%s%3N)
          
          cd ~/mlos-core
          BINARY=$(find . -name "mlos_core" -o -name "mlos-server" 2>/dev/null | head -1)
          if [ -z "$BINARY" ]; then
            # Try nested directory
            BINARY=$(find . -type f -executable -name "mlos_core" 2>/dev/null | head -1)
          fi
          
          if [ -z "$BINARY" ]; then
            echo "âŒ Core binary not found"
            find . -type f -name "*mlos*" 2>/dev/null
            exit 1
          fi
          
          echo "ðŸ“ Found Core binary: $BINARY"
          chmod +x "$BINARY"
          
          export LD_LIBRARY_PATH="$(pwd)/build/onnxruntime/lib:$LD_LIBRARY_PATH"
          echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH" >> $GITHUB_ENV
          
          # Start Core in background
          nohup $BINARY --http-port 18080 > /tmp/core.log 2>&1 &
          echo $! > /tmp/core.pid
          echo "ðŸš€ Core started with PID $(cat /tmp/core.pid)"
          
          # Wait for Core to be ready
          for i in {1..30}; do
            if curl -s http://127.0.0.1:18080/health >/dev/null 2>&1; then
              echo "âœ… Core server ready"
              break
            fi
            echo "â³ Waiting for Core... ($i/30)"
            sleep 1
          done
      
          if ! curl -s http://127.0.0.1:18080/health >/dev/null 2>&1; then
            echo "âŒ Core failed to start"
            cat /tmp/core.log
            exit 1
          fi
          
          END_TIME=$(date +%s%3N)
          CORE_STARTUP_MS=$((END_TIME - START_TIME))
          echo "core_startup_ms=$CORE_STARTUP_MS" >> $GITHUB_OUTPUT
          echo "â±ï¸ Core startup: ${CORE_STARTUP_MS}ms"
          
          # Measure Core idle resource usage
          sleep 2  # Let Core stabilize
          CORE_PID=$(cat /tmp/core.pid 2>/dev/null || echo "")
          if [ -n "$CORE_PID" ] && ps -p "$CORE_PID" > /dev/null 2>&1; then
            CORE_IDLE_CPU=$(ps -p "$CORE_PID" -o %cpu= 2>/dev/null | xargs || echo "0")
            CORE_IDLE_MEM_MB=$(ps -p "$CORE_PID" -o rss= 2>/dev/null | awk '{printf "%.0f", $1/1024}' || echo "0")
            echo "core_idle_cpu=$CORE_IDLE_CPU" >> $GITHUB_OUTPUT
            echo "core_idle_mem_mb=$CORE_IDLE_MEM_MB" >> $GITHUB_OUTPUT
            echo "ðŸ“Š Core idle: CPU=${CORE_IDLE_CPU}%, Memory=${CORE_IDLE_MEM_MB}MB"
          fi
      
      - name: Run all model tests
        id: test
        run: |
          MODELS="${{ steps.get-models.outputs.models }}"
          
          mkdir -p model-results
          chmod +x scripts/test-single-model.sh
          export PATH="$HOME/.local/bin:$PATH"
          
          # Start resource monitoring in background (captures max during tests)
          CORE_PID=$(cat /tmp/core.pid 2>/dev/null || echo "")
          if [ -n "$CORE_PID" ]; then
            # Use bash-based monitoring to avoid YAML heredoc issues
            (
              MAX_CPU=0
              MAX_MEM=0
              TOTAL_CPU=0
              TOTAL_MEM=0
              SAMPLES=0
              
              while ps -p "$CORE_PID" > /dev/null 2>&1; do
                CPU=$(ps -p "$CORE_PID" -o %cpu= 2>/dev/null | xargs || echo "0")
                MEM_KB=$(ps -p "$CORE_PID" -o rss= 2>/dev/null | xargs || echo "0")
                MEM_MB=$((MEM_KB / 1024))
                
                # Update max if higher (using awk for float comparison)
                if [ -n "$CPU" ] && [ -n "$MEM_MB" ]; then
                  CPU_FLOAT=$(echo "$CPU" | awk '{print $1+0}')
                  MAX_CPU_FLOAT=$(echo "$MAX_CPU" | awk '{print $1+0}')
                  
                  if awk "BEGIN {exit !($CPU_FLOAT > $MAX_CPU_FLOAT)}"; then
                    MAX_CPU=$CPU
                  fi
                  if [ "$MEM_MB" -gt "$MAX_MEM" ] 2>/dev/null; then
                    MAX_MEM=$MEM_MB
                  fi
                  
                  # Accumulate for average (using awk)
                  TOTAL_CPU=$(awk "BEGIN {print $TOTAL_CPU + $CPU_FLOAT}")
                  TOTAL_MEM=$((TOTAL_MEM + MEM_MB))
                  SAMPLES=$((SAMPLES + 1))
                  
                  # Write max values
                  echo "$MAX_CPU" > /tmp/core_max_cpu.txt
                  echo "$MAX_MEM" > /tmp/core_max_mem.txt
                  
                  # Write avg values
                  if [ $SAMPLES -gt 0 ]; then
                    AVG_CPU=$(awk "BEGIN {printf \"%.1f\", $TOTAL_CPU / $SAMPLES}")
                    AVG_MEM=$((TOTAL_MEM / SAMPLES))
                    echo "$AVG_CPU" > /tmp/core_avg_cpu.txt
                    echo "$AVG_MEM" > /tmp/core_avg_mem.txt
                  fi
                fi
                
                sleep 0.5
              done
            ) &
            MONITOR_PID=$!
            echo "ðŸ“Š Resource monitor started (PID: $MONITOR_PID) for Core PID: $CORE_PID"
          fi
          
          # Separate NLP (smaller, parallel OK) from Vision (larger, need sequential)
          NLP_MODELS=""
          VISION_MODELS=""
          for model in $MODELS; do
            case "$model" in
              gpt2|bert|roberta|t5) NLP_MODELS="$NLP_MODELS $model" ;;
              *) VISION_MODELS="$VISION_MODELS $model" ;;
            esac
          done
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ðŸ§ª Phase 1: NLP models (parallel:3) -$NLP_MODELS"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Run NLP models in parallel (smaller models, less disk usage)
          if [ -n "$NLP_MODELS" ]; then
            echo "$NLP_MODELS" | tr ' ' '\n' | grep -v '^$' | xargs -P 3 -I {} bash -c '
              export PATH="$HOME/.local/bin:$PATH"
              echo "ðŸ”„ [NLP] Starting: {}"
              ./scripts/test-single-model.sh "{}" \
                --output-dir model-results \
                --core-url http://127.0.0.1:18080 \
                || echo "âš ï¸ {} had issues"
            '
          fi
          
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ðŸ§ª Phase 2: Vision models (sequential) -$VISION_MODELS"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Run Vision models sequentially (large models, need disk cleanup between)
          for model in $VISION_MODELS; do
            [ -z "$model" ] && continue
            echo "ðŸ”„ [Vision] Starting: $model"
            ./scripts/test-single-model.sh "$model" \
            --output-dir model-results \
            --core-url http://127.0.0.1:18080 \
              || echo "âš ï¸ $model had issues"
            
            # Show disk space after each vision model
            echo "ðŸ“Š Disk after $model: $(df -h / | tail -1 | awk '{print $4}') free"
          done
          
          # Stop monitor and get max values
          if [ -n "$MONITOR_PID" ]; then
            kill $MONITOR_PID 2>/dev/null || true
            wait $MONITOR_PID 2>/dev/null || true
            sleep 1
          fi
          
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âœ… All model tests completed"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          ls -la model-results/
          
          # Get max CPU/memory from monitoring
          if [ -f /tmp/core_max_cpu.txt ] && [ -f /tmp/core_max_mem.txt ]; then
            CORE_LOAD_CPU_MAX=$(cat /tmp/core_max_cpu.txt | head -1 || echo "0")
            CORE_LOAD_MEM_MAX_MB=$(cat /tmp/core_max_mem.txt | head -1 || echo "0")
            if [ -f /tmp/core_avg_cpu.txt ] && [ -f /tmp/core_avg_mem.txt ]; then
              CORE_LOAD_CPU_AVG=$(cat /tmp/core_avg_cpu.txt | head -1 || echo "$CORE_LOAD_CPU_MAX")
              CORE_LOAD_MEM_AVG_MB=$(cat /tmp/core_avg_mem.txt | head -1 || echo "$CORE_LOAD_MEM_MAX_MB")
            else
              # Fallback: use max as avg if no samples
              CORE_LOAD_CPU_AVG=$CORE_LOAD_CPU_MAX
              CORE_LOAD_MEM_AVG_MB=$CORE_LOAD_MEM_MAX_MB
            fi
          else
            # Fallback: measure current (may be idle)
            CORE_PID=$(cat /tmp/core.pid 2>/dev/null || echo "")
            if [ -n "$CORE_PID" ] && ps -p "$CORE_PID" > /dev/null 2>&1; then
              CORE_LOAD_CPU_MAX=$(ps -p "$CORE_PID" -o %cpu= 2>/dev/null | xargs || echo "0")
              CORE_LOAD_MEM_MAX_MB=$(ps -p "$CORE_PID" -o rss= 2>/dev/null | awk '{printf "%.0f", $1/1024}' || echo "0")
              CORE_LOAD_CPU_AVG=$CORE_LOAD_CPU_MAX
              CORE_LOAD_MEM_AVG_MB=$CORE_LOAD_MEM_MAX_MB
            else
              CORE_LOAD_CPU_MAX=0
              CORE_LOAD_MEM_MAX_MB=0
              CORE_LOAD_CPU_AVG=0
              CORE_LOAD_MEM_AVG_MB=0
            fi
          fi
          
          echo "core_load_cpu_max=$CORE_LOAD_CPU_MAX" >> $GITHUB_OUTPUT
          echo "core_load_cpu_avg=$CORE_LOAD_CPU_AVG" >> $GITHUB_OUTPUT
          echo "core_load_mem_max_mb=$CORE_LOAD_MEM_MAX_MB" >> $GITHUB_OUTPUT
          echo "core_load_mem_avg_mb=$CORE_LOAD_MEM_AVG_MB" >> $GITHUB_OUTPUT
          echo "ðŸ“Š Core under load: CPU=${CORE_LOAD_CPU_MAX}% (max), Memory=${CORE_LOAD_MEM_MAX_MB}MB (max)"
          
          # Measure Axon (if running)
          AXON_PID=$(pgrep -f "axon" | head -1 || echo "")
          if [ -n "$AXON_PID" ]; then
            AXON_CPU=$(ps -p "$AXON_PID" -o %cpu= 2>/dev/null | xargs || echo "0")
            AXON_MEM_MB=$(ps -p "$AXON_PID" -o rss= 2>/dev/null | awk '{printf "%.0f", $1/1024}' || echo "0")
            echo "axon_cpu=$AXON_CPU" >> $GITHUB_OUTPUT
            echo "axon_mem_mb=$AXON_MEM_MB" >> $GITHUB_OUTPUT
            echo "ðŸ“Š Axon: CPU=${AXON_CPU}%, Memory=${AXON_MEM_MB}MB"
          fi
        continue-on-error: true
      
      - name: Stop Core server
        if: always()
        run: |
          if [ -f /tmp/core.pid ]; then
            kill $(cat /tmp/core.pid) 2>/dev/null || true
            echo "ðŸ›‘ Core server stopped"
          fi
          
          echo "ðŸ“‹ Core logs:"
          cat /tmp/core.log 2>/dev/null | tail -100 || true
      
      - name: Collect hardware and timing info
        if: always()
        run: |
          mkdir -p model-results
          
          # Collect actual hardware info from runner
          cat > model-results/hardware-info.json << EOF
          {
            "os": "$(uname -s)",
            "os_version": "$(cat /etc/os-release 2>/dev/null | grep PRETTY_NAME | cut -d'"' -f2 || uname -r)",
            "arch": "$(uname -m)",
            "cpu_model": "$(lscpu 2>/dev/null | grep 'Model name' | cut -d':' -f2 | xargs || echo 'Unknown')",
            "cpu_cores": $(nproc --all 2>/dev/null || echo 2),
            "cpu_threads": $(nproc 2>/dev/null || echo 2),
            "memory_gb": $(free -g 2>/dev/null | awk '/^Mem:/{print $2}' || echo 7),
            "gpu_count": $(nvidia-smi -L 2>/dev/null | wc -l || echo 0),
            "gpu_name": "$(nvidia-smi --query-gpu=name --format=csv,noheader 2>/dev/null | head -1 || echo 'None')",
            "gpu_memory": "$(nvidia-smi --query-gpu=memory.total --format=csv,noheader 2>/dev/null | head -1 || echo 'N/A')",
            "disk_total": "$(df -h / | tail -1 | awk '{print $2}')",
            "disk_available": "$(df -h / | tail -1 | awk '{print $4}')"
          }
          EOF
          
          # Collect timing info from previous steps
          cat > model-results/timings-info.json << EOF
          {
            "axon_download_ms": ${{ steps.axon-download.outputs.axon_download_ms || 0 }},
            "core_download_ms": ${{ steps.core-download.outputs.core_download_ms || 0 }},
            "core_startup_ms": ${{ steps.core-startup.outputs.core_startup_ms || 0 }}
          }
          EOF
          
          # Collect resource usage info from previous steps
          cat > model-results/resources-info.json << EOF
          {
            "core_idle_cpu": ${{ steps.core-startup.outputs.core_idle_cpu || 0 }},
            "core_idle_mem_mb": ${{ steps.core-startup.outputs.core_idle_mem_mb || 0 }},
            "core_load_cpu_avg": ${{ steps.test.outputs.core_load_cpu_max || 0 }},
            "core_load_cpu_max": ${{ steps.test.outputs.core_load_cpu_max || 0 }},
            "core_load_mem_avg_mb": ${{ steps.test.outputs.core_load_mem_max_mb || 0 }},
            "core_load_mem_max_mb": ${{ steps.test.outputs.core_load_mem_max_mb || 0 }},
            "axon_cpu": ${{ steps.test.outputs.axon_cpu || 0 }},
            "axon_mem_mb": ${{ steps.test.outputs.axon_mem_mb || 0 }},
            "gpu_status": "Not used (CPU-only inference)"
          }
          EOF
          
          echo "ðŸ“Š Hardware Info:"
          cat model-results/hardware-info.json
          echo ""
          echo "â±ï¸ Timing Info:"
          cat model-results/timings-info.json
      
      - name: Aggregate results
        if: always()
        run: |
          mkdir -p output metrics
          
          python3 scripts/aggregate-results.py \
            --results-dir model-results \
            --output metrics/latest.json \
            --markdown output/RESULTS.md \
            --hardware-info model-results/hardware-info.json \
            --timings-info model-results/timings-info.json \
            --resources-info model-results/resources-info.json \
            --github-summary || echo "âš ï¸ Aggregation had issues"
          
          echo "ðŸ“Š Metrics:"
          cat metrics/latest.json 2>/dev/null || echo "{}"
      
      - name: Generate HTML report
        if: always()
        run: |
          python3 report/render.py \
            --metrics metrics/latest.json \
            --template report/template.html \
            --output output/index.html || echo "âš ï¸ Renderer failed"
          
          cp report/styles.css output/ 2>/dev/null || true
          
          # Fallback
          if [ ! -f output/index.html ]; then
            echo "<html><body><h1>E2E Results</h1><pre>$(cat output/RESULTS.md 2>/dev/null || echo 'No results')</pre></body></html>" > output/index.html
          fi
          
          ls -la output/
      
      - name: Upload metrics
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-metrics-${{ github.run_number }}
          path: metrics/
          retention-days: 90
      
      - name: Upload report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-report-${{ github.run_number }}
          path: output/
          retention-days: 90
      
      - name: Upload model results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-model-results-${{ github.run_number }}
          path: model-results/
          retention-days: 30
      
      - name: Upload logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-logs-${{ github.run_number }}
          path: /tmp/core.log
          retention-days: 30
      
      - name: Setup Pages
        if: always()
        uses: actions/configure-pages@v4
      
      - name: Prepare Pages artifact
        if: always()
        run: |
          # Create a clean output directory without symlinks or hard links
          mkdir -p ./output-clean
          # Copy all files recursively, breaking symlinks and hard links
          if [ -d ./output ]; then
            # Copy entire directory structure, breaking all symlinks and hard links
            # Use tar to copy, which naturally breaks links
            (cd ./output && tar -cf - .) | (cd ./output-clean && tar -xf -) 2>/dev/null || \
            # Fallback: use cp with proper options
            cp -rL --no-preserve=links ./output/. ./output-clean/ 2>/dev/null || true
            # Remove any remaining symlinks (shouldn't be any, but just in case)
            find ./output-clean -type l -delete 2>/dev/null || true
            # Remove large files (>10MB) to reduce size
            find ./output-clean -type f -size +10M -delete 2>/dev/null || true
            # Replace output with clean version
            rm -rf ./output
            mv ./output-clean ./output
            echo "âœ… Cleaned output directory (removed symlinks and hard links)"
          else
            echo "âš ï¸ Output directory not found"
          fi
          # Verify no symlinks or hard links remain
          SYMLINKS=$(find ./output -type l 2>/dev/null | wc -l)
          HARD_LINKS=$(find ./output -type f -links +1 2>/dev/null | wc -l)
          echo "Symlinks found: $SYMLINKS"
          echo "Hard links found: $HARD_LINKS"
          ls -lah ./output/ 2>/dev/null | head -20
          du -sh ./output/ 2>/dev/null || echo "Cannot check size"

      - name: Upload Pages artifact
        if: always()
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./output
      
      - name: Deploy to GitHub Pages
        if: always()
        id: deployment
        uses: actions/deploy-pages@v4
      
      - name: Summary
        if: always()
        run: |
          echo "## ðŸ“Š E2E Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸŒ **Report**: https://mlos-foundation.github.io/system-test/" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f metrics/latest.json ]; then
          echo -e "import json\ntry:\n    with open(\"metrics/latest.json\") as f:\n        m = json.load(f)\n    print(\"| Metric | Value |\")\n    print(\"|--------|-------|\")\n    total = m.get(\"total_models\", \"N/A\")\n    success = m.get(\"successful_models\", \"N/A\")\n    rate = m.get(\"success_rate\", \"N/A\")\n    print(\"| Models Tested | {}\" .format(total))\n    print(\"| Successful | {}\" .format(success))\n    print(\"| Success Rate | {}%\" .format(rate))\nexcept:\n    print(\"Results not available\")" > /tmp/summary.py && python3 /tmp/summary.py >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Benefits of Single Runner:" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Consistent hardware for all models" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Comparable performance metrics" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Single Core instance" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… No repeated downloads" >> $GITHUB_STEP_SUMMARY
